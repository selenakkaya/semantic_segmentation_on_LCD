{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3614dc9d-1d3e-417b-873a-73e424472e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rail-demo-367913'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a2cd8b-26dc-43af-a992-41b0f0db348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'europe-west4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0b2730-638b-4c3a-a537-9dfaed5f03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a54e500-37f4-49e0-b37b-390bb782a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec1303a-af80-4951-b503-bf7a62e98827",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337d2d9-2487-4cda-ad51-ffd4224afb41",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Storage Bucket\n",
    "Check to see if bucket already exist and create if missing:\n",
    "- [GCS Python Client](https://cloud.google.com/python/docs/reference/storage/latest/google.cloud.storage.client.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f3c84a-1912-47e8-9a11-9218520ad90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket already exist: rail-demo-367913\n"
     ]
    }
   ],
   "source": [
    "if not gcs.lookup_bucket(BUCKET):\n",
    "    bucketDef = gcs.bucket(BUCKET)\n",
    "    bucket = gcs.create_bucket(bucketDef, project=PROJECT_ID, location=REGION)\n",
    "    print(f'Created Bucket: {gcs.lookup_bucket(BUCKET).name}')\n",
    "else:\n",
    "    bucketDef = gcs.bucket(BUCKET)\n",
    "    print(f'Bucket already exist: {bucketDef.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5ddcd2-ac8d-4929-a035-0cdb45c2d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the storage bucket in the console here:\n",
      "https://console.cloud.google.com/storage/browser/rail-demo-367913;tab=objects&project=rail-demo-367913\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the storage bucket in the console here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID};tab=objects&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634c7f0-2f35-4253-adc0-644b6dc6454c",
   "metadata": {},
   "source": [
    "---\n",
    "<a id = 'permissions'></a>\n",
    "## Service Account & Permissions\n",
    "\n",
    "This notebook instance is running as a service account in GCP.  This service account will also be used to run other services in Vertex AI like training jobs and pipelines.  The service account will need permission to interact with object in Cloud Storage which requires the role ([roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles)).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893e6ffc-72bb-4487-a4c7-f6967b07da6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'595378874286-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d593a267-d729-4c63-93ec-4c6a4404284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable cloudresourcemanager.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5fe3c5-e563-4e00-a220-cd9bf10b4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/owner\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d46d8e-0a00-4806-b89e-c810dffcaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp -U -q\n",
    "!pip install google-cloud-pipeline-components -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed296b-c3be-4776-90ce-058601f36f87",
   "metadata": {},
   "source": [
    "---\n",
    "## Update AIPlatform Package:\n",
    "\n",
    "The `google-cloud-aiplatform` package updates frequently.  Update it for latest functionality.\n",
    "\n",
    "- [aiplatform Python Client](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "- [GitHub Repo for api-common-protos](https://github.com/googleapis/api-common-protos)\n",
    "\n",
    "For a better understanding of the Vertex AI APIs client, version, and layers please review the tip here [aiplatform_notes.md](../Tips/aiplatform_notes.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c39a39b-dfb5-4409-9938-3d08b6b191d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googleapis-common-protos -U -q\n",
    "!pip install google-cloud-aiplatform -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5decaf8d-8d3c-4448-92c5-5bb165433504",
   "metadata": {},
   "source": [
    "# MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db967f4-b9db-4171-87f8-53e62726a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID\n",
    "\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bf15e3-1cc0-4faf-9792-4e4923e0a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source data\n",
    "RAIL_PROJECT = PROJECT_ID\n",
    "RAIL_DATASET = 'rail-demo-367913'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0675b570-66aa-4de1-87ab-bf30138c6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff51615-1195-42eb-a977-b9dc4e675f47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucketDef' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29626/3195052252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucketDef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bucketDef' is not defined"
     ]
    }
   ],
   "source": [
    "list(bucketDef.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae41ad0-4884-4ce6-b950-21c37e3d20f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"#to download files from cloud storage\n",
    "bucket_name = \"rail-demo-367913\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# When you have your files in a subfolder of the bucket.\n",
    "my_prefix = \"saved_arrays_multiclass/\" # the name of the subfolder\n",
    "blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n",
    "\n",
    "for blob in blobs:\n",
    "    if(blob.name != my_prefix): # ignoring the subfolder itself \n",
    "        file_name = blob.name.replace(my_prefix, \"\")\n",
    "        blob.download_to_filename(file_name) # download the file to the machine\n",
    "        df = np.load(file_name) # load the data\n",
    "        print(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a493cc90-10af-4e0d-aac6-49e8e091b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25445fef-adc1-4738-9ea4-6428058cf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 512\n",
    "EPOCHS = 1\n",
    "PATIENCE =1\n",
    "BATCH_SIZE = 8\n",
    "OPTIMIZER = 'adam'\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 3\n",
    "DIM = 512\n",
    "MODEL_NAME = \"unet_multiclass.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dcf496b-00c3-4bf7-8f9e-b82b9a80687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images (858, 512, 512, 3)\n",
      "train masks (858, 512, 512, 3)\n",
      "val images (167, 512, 512, 3)\n",
      "test images (118, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_path = \"saved_arrays_multiclass\"\n",
    "train_images = np.load(src_path + \"/train_images.npy\") #FIXME aggiungere tutte le immagini\n",
    "train_masks = np.load(src_path + \"/train_masks.npy\")\n",
    "val_images = np.load(src_path + \"/val_images.npy\")\n",
    "val_masks = np.load(src_path + \"/val_masks.npy\")\n",
    "test_images = np.load(src_path + \"/test_images.npy\")\n",
    "test_masks = np.load(src_path + \"/test_masks.npy\")\n",
    "print(\"train images\", train_images.shape)\n",
    "print(\"train masks\", train_masks.shape)\n",
    "print(\"val images\", val_images.shape)\n",
    "print(\"test images\", test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91b0017d-e1a4-45f8-bbbb-71e9e0d1b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = train_images/255.0\n",
    "val_images = val_images/255.0\n",
    "test_images = test_images/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcefa8ef-af0e-427b-aee7-12243d7eef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"checkpoints\" #where to save the model checkpoints\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09076897-604b-4fdd-97ae-c51f06870b57",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1d1e36-1825-4612-a0f9-5206db3c193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Unet by dividing encoder and decoder into blocks\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    \n",
    "\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")(d4)  #Change the activation based on n_classes\n",
    "    \n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d9e15e-d50f-4500-9ff6-54b2a9f1e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 10:31:08.922508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:08.931471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:08.931733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:08.932899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-21 10:31:08.934945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:08.935185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:08.935351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:09.405150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:09.405459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:09.405654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 10:31:09.405815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 256 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 1024) 4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 256 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 256 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 256 590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 256 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 128 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 128 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 3)  195         activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,055,427\n",
      "Trainable params: 31,043,651\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_unet((DIM,DIM,3), n_classes=3)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab94486-5c8b-47d4-81b5-8cb48bedad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_callbacks():\n",
    "    checkpointer = [\n",
    "          EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "          ModelCheckpoint(checkpoint_path + '/'+ MODEL_NAME,  monitor=\"val_loss\", save_best_only=True) #best on iou\n",
    "    ]\n",
    "    return checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c58dc0f1-a760-47a9-b4c9-728c6010875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 10:31:14.841626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-12-21 10:31:16.935419: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "2022-12-21 10:31:20.170155: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 529.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.170285: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 556.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.244938: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 529.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.398418: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.474104: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.474165: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2022-12-21 10:31:20.474325: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-21 10:31:20.815112: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 123s 1s/step - loss: 2.0462 - accuracy: 0.7033 - val_loss: 3023.9531 - val_accuracy: 0.2067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75c45f2490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_masks,  batch_size=BATCH_SIZE, verbose=1, epochs=EPOCHS, validation_data=(val_images, val_masks), callbacks = build_callbacks())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c927978-40c1-48a1-a1d8-c1424f30ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_masks(raw, mask):\n",
    "    pred = model.predict(np.expand_dims(raw, 0))\n",
    "    pred1 = np.argmax(pred, axis=-1)[0,:,:]\n",
    "    pred_msk = np.stack((pred1,) * 3, axis=-1)\n",
    "    pred_msk[(pred_msk[:, :, 0] == 1) & (pred_msk[:, :, 1] == 1) & (pred_msk[:, :, 2] == 1)] = (255,0,0)\n",
    "    pred_msk[(pred_msk[:, :, 0] == 2) & (pred_msk[:, :, 1] == 2) & (pred_msk[:, :, 2] == 2)] = (0,255,0)\n",
    "\n",
    "    mask1 = np.argmax(mask, axis=-1)\n",
    "    target_msk = np.stack((mask1,) * 3, axis=-1)\n",
    "    target_msk[(target_msk[:, :, 0] == 1) & (target_msk[:, :, 1] == 1) & (target_msk[:, :, 2] == 1)] = (255,0,0)\n",
    "    target_msk[(target_msk[:, :, 0] == 2) & (target_msk[:, :, 1] == 2) & (target_msk[:, :, 2] == 2)] = (0,255,0)\n",
    "\n",
    "    raw = np.float32(raw)\n",
    "    pred_msk = np.float32(pred_msk)\n",
    "    target_msk = np.float32(target_msk)\n",
    "    raw = cv2.cvtColor(raw, cv2.COLOR_RGB2BGR)\n",
    "    pred_msk = cv2.cvtColor(pred_msk, cv2.COLOR_RGB2BGR)\n",
    "    target_msk = cv2.cvtColor(target_msk, cv2.COLOR_RGB2BGR)\n",
    "    combined = np.concatenate([raw, pred_msk, target_msk], axis=1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "846e641a-9645-4a2e-bf3a-8cb705e54ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_dir = \"samples_multiclass\" #where to save the predictions\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_img = test_images[i]\n",
    "    test_mask = test_masks[i]\n",
    "    combined = plot_img_and_masks(test_img, test_mask)\n",
    "    cv2.imwrite(sample_dir + \"/\" + str(i) + '.jpg', combined * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f0d62f-d72b-4e0a-8f79-25a129b537e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 512, 512, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fa0a5a3-9b7a-40cf-8e53-930aad30b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS\n",
      "mean iou 0.028325346323320552\n",
      "[0.008921519008785992, 0.069644213255069, 0.00641030670610666]\n",
      "dice coeff. 0.053547870128536755\n",
      "[0.01768525864638298, 0.130219398921689, 0.01273895281753828]\n",
      "pixel acc. 0.3342898308479598\n",
      "[0.008929896181743417, 0.24782087490094887, 0.7461187214611872]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Quantitative measures\"\"\"\n",
    "\n",
    "from evaluation_multiclass import mean_iou_test, dice_coeff, pixel_accuracy\n",
    "\n",
    "print(\"TEST RESULTS\")\n",
    "pred_masks = model.predict(test_images) #(n examples,h,w,3)\n",
    "\n",
    "test_masks1 = np.argmax(test_masks, axis=-1) #(n examples,h,w)\n",
    "pred_masks1 = np.argmax(pred_masks, axis=-1)\n",
    "\n",
    "iou, iou_classes = mean_iou_test(test_masks1, pred_masks1,num_classes=3)\n",
    "print(\"mean iou\", iou)\n",
    "print(iou_classes)\n",
    "dice, dice_classes = dice_coeff(test_masks1, pred_masks1,num_classes=3)\n",
    "print(\"dice coeff.\", dice)\n",
    "print(dice_classes)\n",
    "acc, acc_classes = pixel_accuracy(test_masks1, pred_masks1,num_classes=3)\n",
    "print(\"pixel acc.\", acc)\n",
    "print(acc_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec2e62-772f-4196-ae72-6c045ecb7226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6431d7-580c-4cd1-a27f-f05e51da3bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
