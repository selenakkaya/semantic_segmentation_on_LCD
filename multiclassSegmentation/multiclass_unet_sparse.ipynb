{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a493cc90-10af-4e0d-aac6-49e8e091b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25445fef-adc1-4738-9ea4-6428058cf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIM = 512\n",
    "EPOCHS = ...\n",
    "PATIENCE = ...\n",
    "BATCH_SIZE = ...\n",
    "OPTIMIZER = \"...\"\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 3\n",
    "MODEL_NAME = \"unet_multiclass.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7dcf496b-00c3-4bf7-8f9e-b82b9a80687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]]\n",
      "(858, 512, 512, 1)\n",
      "[[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]]\n",
      "\n",
      "\n",
      " [[[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]]\n",
      "\n",
      "\n",
      " [[[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]\n",
      "\n",
      "  [[1]\n",
      "   [1]\n",
      "   [1]\n",
      "   ...\n",
      "   [1]\n",
      "   [1]\n",
      "   [1]]]]\n",
      "(167, 512, 512, 1)\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 2 2 1]\n",
      "  [1 1 1 ... 2 2 0]\n",
      "  [1 1 1 ... 1 0 1]\n",
      "  ...\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [1 1 1 ... 0 0 0]]]\n",
      "(118, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "src_path = \"saved_arrays_multiclass/\"\n",
    "\n",
    "train_images = np.load(src_path + \"train_images.npy\")\n",
    "train_masks_one_hot = np.load(src_path + \"train_masks.npy\")\n",
    "train_masks = np.argmax(train_masks_one_hot, axis=-1)\n",
    "train_masks = np.expand_dims(train_masks, axis=-1)\n",
    "print(train_masks.shape)\n",
    "\n",
    "\n",
    "val_images = np.load(src_path + \"val_images.npy\")\n",
    "val_masks_one_hot = np.load(src_path + \"val_masks.npy\")\n",
    "val_masks = np.argmax(val_masks_one_hot, axis=-1)\n",
    "val_masks = np.expand_dims(val_masks, axis=-1)\n",
    "print(val_masks.shape)\n",
    "\n",
    "test_images = np.load(src_path + \"test_images.npy\")\n",
    "test_masks_one_hot = np.load(src_path + \"test_masks.npy\")\n",
    "test_masks = np.argmax(test_masks_one_hot, axis=-1)\n",
    "test_masks = np.expand_dims(test_masks, axis=-1)\n",
    "print(test_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91b0017d-e1a4-45f8-bbbb-71e9e0d1b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "val_images = val_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcefa8ef-af0e-427b-aee7-12243d7eef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09076897-604b-4fdd-97ae-c51f06870b57",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c1d1e36-1825-4612-a0f9-5206db3c193c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet(sz, n_classes=3):\n",
    "   \"\"\"...\"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef2b0313-9e4e-43b4-9c5d-ed9d2f064f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = unet((DIM,DIM,3), n_classes=3)\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50755a6f-c50b-470f-8b56-0a2a35925e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"...\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42cd9c3b-c556-4e06-aeca-15812b698089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 512, 512, 8)  224         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 512, 512, 8)  584         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 256, 256, 8)  0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 256, 256, 16) 1168        max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 256, 256, 16) 2320        conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 128, 128, 16) 0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 128, 128, 32) 4640        max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 64, 64, 64)   18496       max_pooling2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 32, 32, 128)  73856       max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 256)  295168      max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 512)    1180160     max_pooling2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 512)    2359808     conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_42 (Conv2DTran (None, 16, 16, 64)   131136      conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 16, 16, 320)  0           conv2d_transpose_42[0][0]        \n",
      "                                                                 conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 256)  737536      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_43 (Conv2DTran (None, 32, 32, 32)   32800       conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 32, 32, 160)  0           conv2d_transpose_43[0][0]        \n",
      "                                                                 conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 128)  184448      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_44 (Conv2DTran (None, 64, 64, 16)   8208        conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 64, 64, 80)   0           conv2d_transpose_44[0][0]        \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 64, 64, 64)   46144       concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_45 (Conv2DTran (None, 128, 128, 8)  2056        conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 128, 128, 40) 0           conv2d_transpose_45[0][0]        \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 128, 128, 32) 11552       concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_46 (Conv2DTran (None, 256, 256, 4)  516         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 256, 256, 20) 0           conv2d_transpose_46[0][0]        \n",
      "                                                                 conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 256, 256, 16) 2896        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 256, 256, 16) 2320        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_47 (Conv2DTran (None, 512, 512, 2)  130         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 512, 512, 10) 0           conv2d_transpose_47[0][0]        \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 512, 512, 16) 1456        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 512, 512, 16) 2320        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 512, 512, 3)  51          conv2d_214[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,667,673\n",
      "Trainable params: 6,667,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0bb8333e-cffc-45c4-8ddf-6a4954e317a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_callbacks():\n",
    "    checkpointer = [\n",
    "          EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "          ModelCheckpoint(checkpoint_path + '/' + MODEL_NAME,  monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "    return checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02025b82-ae31-4745-984a-2de3e554a02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "108/108 [==============================] - 14s 107ms/step - loss: 0.8185 - accuracy: 0.6204 - val_loss: 0.7746 - val_accuracy: 0.6561\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.7914 - accuracy: 0.6227 - val_loss: 0.7397 - val_accuracy: 0.6645\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7323 - accuracy: 0.6790 - val_loss: 0.6821 - val_accuracy: 0.7219\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6968 - accuracy: 0.6951 - val_loss: 0.6710 - val_accuracy: 0.7211\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6937 - accuracy: 0.6987 - val_loss: 0.6749 - val_accuracy: 0.7195\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6947 - accuracy: 0.6983 - val_loss: 0.6868 - val_accuracy: 0.7072\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6920 - accuracy: 0.6977 - val_loss: 0.6948 - val_accuracy: 0.6960\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6951 - accuracy: 0.6968 - val_loss: 0.6847 - val_accuracy: 0.7126\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6850 - accuracy: 0.7024 - val_loss: 0.6642 - val_accuracy: 0.7247\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6742 - accuracy: 0.7079 - val_loss: 0.6576 - val_accuracy: 0.7291\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6775 - accuracy: 0.7070 - val_loss: 0.6733 - val_accuracy: 0.7144\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6810 - accuracy: 0.7049 - val_loss: 0.6714 - val_accuracy: 0.7199\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6692 - accuracy: 0.7131 - val_loss: 0.6443 - val_accuracy: 0.7412\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6735 - accuracy: 0.7109 - val_loss: 0.6469 - val_accuracy: 0.7397\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6715 - accuracy: 0.7124 - val_loss: 0.6592 - val_accuracy: 0.7267\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6643 - accuracy: 0.7173 - val_loss: 0.6329 - val_accuracy: 0.7485\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 10s 97ms/step - loss: 0.6623 - accuracy: 0.7191 - val_loss: 0.6272 - val_accuracy: 0.7512\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.8280 - accuracy: 0.6699 - val_loss: 0.7695 - val_accuracy: 0.6563\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7937 - accuracy: 0.6226 - val_loss: 0.7671 - val_accuracy: 0.6581\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7688 - accuracy: 0.6496 - val_loss: 0.6972 - val_accuracy: 0.7295\n",
      "Epoch 21/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7285 - accuracy: 0.6901 - val_loss: 0.6701 - val_accuracy: 0.7396\n",
      "Epoch 22/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7034 - accuracy: 0.7063 - val_loss: 0.6726 - val_accuracy: 0.7432\n",
      "Epoch 23/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6946 - accuracy: 0.7131 - val_loss: 0.6574 - val_accuracy: 0.7416\n",
      "Epoch 24/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.7029 - accuracy: 0.7067 - val_loss: 0.7018 - val_accuracy: 0.7072\n",
      "Epoch 25/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6875 - accuracy: 0.7163 - val_loss: 0.6486 - val_accuracy: 0.7503\n",
      "Epoch 26/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6752 - accuracy: 0.7238 - val_loss: 0.6591 - val_accuracy: 0.7445\n",
      "Epoch 27/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6813 - accuracy: 0.7181 - val_loss: 0.6333 - val_accuracy: 0.7571\n",
      "Epoch 28/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6746 - accuracy: 0.7212 - val_loss: 0.6821 - val_accuracy: 0.7118\n",
      "Epoch 29/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6807 - accuracy: 0.7197 - val_loss: 0.6285 - val_accuracy: 0.7590\n",
      "Epoch 30/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6625 - accuracy: 0.7263 - val_loss: 0.6160 - val_accuracy: 0.7632\n",
      "Epoch 31/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6505 - accuracy: 0.7315 - val_loss: 0.6128 - val_accuracy: 0.7670\n",
      "Epoch 32/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6501 - accuracy: 0.7320 - val_loss: 0.6321 - val_accuracy: 0.7454\n",
      "Epoch 33/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6386 - accuracy: 0.7379 - val_loss: 0.6026 - val_accuracy: 0.7634\n",
      "Epoch 34/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6281 - accuracy: 0.7411 - val_loss: 0.5970 - val_accuracy: 0.7685\n",
      "Epoch 35/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.6332 - accuracy: 0.7382 - val_loss: 0.5774 - val_accuracy: 0.7750\n",
      "Epoch 36/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6110 - accuracy: 0.7467 - val_loss: 0.6087 - val_accuracy: 0.7429\n",
      "Epoch 37/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5972 - accuracy: 0.7511 - val_loss: 0.5742 - val_accuracy: 0.7765\n",
      "Epoch 38/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.6010 - accuracy: 0.7488 - val_loss: 0.5536 - val_accuracy: 0.7832\n",
      "Epoch 39/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5782 - accuracy: 0.7631 - val_loss: 0.5668 - val_accuracy: 0.7879\n",
      "Epoch 40/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5774 - accuracy: 0.7661 - val_loss: 0.5764 - val_accuracy: 0.7573\n",
      "Epoch 41/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.5639 - accuracy: 0.7711 - val_loss: 0.5803 - val_accuracy: 0.7565\n",
      "Epoch 42/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5507 - accuracy: 0.7782 - val_loss: 0.5368 - val_accuracy: 0.7859\n",
      "Epoch 43/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5470 - accuracy: 0.7791 - val_loss: 0.5092 - val_accuracy: 0.7993\n",
      "Epoch 44/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5259 - accuracy: 0.7878 - val_loss: 0.5128 - val_accuracy: 0.7957\n",
      "Epoch 45/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5228 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.8078\n",
      "Epoch 46/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.5290 - accuracy: 0.7866 - val_loss: 0.6033 - val_accuracy: 0.7346\n",
      "Epoch 47/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5201 - accuracy: 0.7914 - val_loss: 0.4940 - val_accuracy: 0.8092\n",
      "Epoch 48/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5125 - accuracy: 0.7943 - val_loss: 0.4874 - val_accuracy: 0.8096\n",
      "Epoch 49/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.5037 - accuracy: 0.7987 - val_loss: 0.4901 - val_accuracy: 0.8089\n",
      "Epoch 50/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4984 - accuracy: 0.8013 - val_loss: 0.4847 - val_accuracy: 0.8101\n",
      "Epoch 51/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4921 - accuracy: 0.8046 - val_loss: 0.4743 - val_accuracy: 0.8128\n",
      "Epoch 52/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.4826 - accuracy: 0.8077 - val_loss: 0.4619 - val_accuracy: 0.8209\n",
      "Epoch 53/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4769 - accuracy: 0.8108 - val_loss: 0.4584 - val_accuracy: 0.8206\n",
      "Epoch 54/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4634 - accuracy: 0.8184 - val_loss: 0.4468 - val_accuracy: 0.8281\n",
      "Epoch 55/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4630 - accuracy: 0.8179 - val_loss: 0.4602 - val_accuracy: 0.8207\n",
      "Epoch 56/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4611 - accuracy: 0.8186 - val_loss: 0.4370 - val_accuracy: 0.8298\n",
      "Epoch 57/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4454 - accuracy: 0.8253 - val_loss: 0.4597 - val_accuracy: 0.8181\n",
      "Epoch 58/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.4444 - accuracy: 0.8259 - val_loss: 0.4300 - val_accuracy: 0.8327\n",
      "Epoch 59/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4353 - accuracy: 0.8295 - val_loss: 0.4195 - val_accuracy: 0.8368\n",
      "Epoch 60/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4268 - accuracy: 0.8334 - val_loss: 0.3991 - val_accuracy: 0.8479\n",
      "Epoch 61/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4190 - accuracy: 0.8372 - val_loss: 0.4475 - val_accuracy: 0.8231\n",
      "Epoch 62/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4257 - accuracy: 0.8342 - val_loss: 0.4277 - val_accuracy: 0.8339\n",
      "Epoch 63/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.4191 - accuracy: 0.8377 - val_loss: 0.4421 - val_accuracy: 0.8265\n",
      "Epoch 64/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4037 - accuracy: 0.8439 - val_loss: 0.4251 - val_accuracy: 0.8358\n",
      "Epoch 65/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.4057 - accuracy: 0.8424 - val_loss: 0.3868 - val_accuracy: 0.8543\n",
      "Epoch 66/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3976 - accuracy: 0.8472 - val_loss: 0.4238 - val_accuracy: 0.8357\n",
      "Epoch 67/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3857 - accuracy: 0.8516 - val_loss: 0.3849 - val_accuracy: 0.8517\n",
      "Epoch 68/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3839 - accuracy: 0.8527 - val_loss: 0.4007 - val_accuracy: 0.8416\n",
      "Epoch 69/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3698 - accuracy: 0.8575 - val_loss: 0.3555 - val_accuracy: 0.8649\n",
      "Epoch 70/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3614 - accuracy: 0.8636 - val_loss: 0.3706 - val_accuracy: 0.8589\n",
      "Epoch 71/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3558 - accuracy: 0.8643 - val_loss: 0.3649 - val_accuracy: 0.8598\n",
      "Epoch 72/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3601 - accuracy: 0.8619 - val_loss: 0.4003 - val_accuracy: 0.8407\n",
      "Epoch 73/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.3547 - accuracy: 0.8640 - val_loss: 0.3495 - val_accuracy: 0.8656\n",
      "Epoch 74/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3455 - accuracy: 0.8689 - val_loss: 0.3612 - val_accuracy: 0.8624\n",
      "Epoch 75/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3396 - accuracy: 0.8708 - val_loss: 0.3864 - val_accuracy: 0.8541\n",
      "Epoch 76/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3338 - accuracy: 0.8733 - val_loss: 0.3617 - val_accuracy: 0.8599\n",
      "Epoch 77/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3353 - accuracy: 0.8718 - val_loss: 0.3321 - val_accuracy: 0.8752\n",
      "Epoch 78/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3509 - accuracy: 0.8662 - val_loss: 0.3377 - val_accuracy: 0.8733\n",
      "Epoch 79/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3355 - accuracy: 0.8727 - val_loss: 0.3325 - val_accuracy: 0.8724\n",
      "Epoch 80/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.3271 - accuracy: 0.8756 - val_loss: 0.3298 - val_accuracy: 0.8735\n",
      "Epoch 81/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.3190 - accuracy: 0.8793 - val_loss: 0.3923 - val_accuracy: 0.8440\n",
      "Epoch 82/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3121 - accuracy: 0.8815 - val_loss: 0.3217 - val_accuracy: 0.8775\n",
      "Epoch 83/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3045 - accuracy: 0.8852 - val_loss: 0.3211 - val_accuracy: 0.8773\n",
      "Epoch 84/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3066 - accuracy: 0.8845 - val_loss: 0.3528 - val_accuracy: 0.8648\n",
      "Epoch 85/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3029 - accuracy: 0.8861 - val_loss: 0.3177 - val_accuracy: 0.8792\n",
      "Epoch 86/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.3062 - accuracy: 0.8846 - val_loss: 0.3362 - val_accuracy: 0.8719\n",
      "Epoch 87/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2924 - accuracy: 0.8901 - val_loss: 0.3159 - val_accuracy: 0.8788\n",
      "Epoch 88/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3149 - accuracy: 0.8804 - val_loss: 0.3561 - val_accuracy: 0.8634\n",
      "Epoch 89/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3070 - accuracy: 0.8836 - val_loss: 0.3358 - val_accuracy: 0.8705\n",
      "Epoch 90/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2930 - accuracy: 0.8901 - val_loss: 0.3259 - val_accuracy: 0.8771\n",
      "Epoch 91/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2852 - accuracy: 0.8933 - val_loss: 0.3129 - val_accuracy: 0.8802\n",
      "Epoch 92/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.2821 - accuracy: 0.8941 - val_loss: 0.3072 - val_accuracy: 0.8842\n",
      "Epoch 93/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2836 - accuracy: 0.8933 - val_loss: 0.3209 - val_accuracy: 0.8794\n",
      "Epoch 94/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2804 - accuracy: 0.8956 - val_loss: 0.3056 - val_accuracy: 0.8855\n",
      "Epoch 95/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2716 - accuracy: 0.8986 - val_loss: 0.3154 - val_accuracy: 0.8823\n",
      "Epoch 96/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2739 - accuracy: 0.8975 - val_loss: 0.3018 - val_accuracy: 0.8869\n",
      "Epoch 97/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2769 - accuracy: 0.8965 - val_loss: 0.3144 - val_accuracy: 0.8809\n",
      "Epoch 98/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.2763 - accuracy: 0.8971 - val_loss: 0.3052 - val_accuracy: 0.8849\n",
      "Epoch 99/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2692 - accuracy: 0.8993 - val_loss: 0.3076 - val_accuracy: 0.8847\n",
      "Epoch 100/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2671 - accuracy: 0.9008 - val_loss: 0.3004 - val_accuracy: 0.8882\n",
      "Epoch 101/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2747 - accuracy: 0.8976 - val_loss: 0.3094 - val_accuracy: 0.8847\n",
      "Epoch 102/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2646 - accuracy: 0.9009 - val_loss: 0.3087 - val_accuracy: 0.8840\n",
      "Epoch 103/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2544 - accuracy: 0.9059 - val_loss: 0.3320 - val_accuracy: 0.8793\n",
      "Epoch 104/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.2586 - accuracy: 0.9039 - val_loss: 0.3011 - val_accuracy: 0.8872\n",
      "Epoch 105/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2531 - accuracy: 0.9066 - val_loss: 0.3133 - val_accuracy: 0.8826\n",
      "Epoch 106/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2557 - accuracy: 0.9051 - val_loss: 0.3084 - val_accuracy: 0.8850\n",
      "Epoch 107/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2395 - accuracy: 0.9120 - val_loss: 0.3502 - val_accuracy: 0.8716\n",
      "Epoch 108/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2473 - accuracy: 0.9084 - val_loss: 0.3100 - val_accuracy: 0.8850\n",
      "Epoch 109/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2398 - accuracy: 0.9119 - val_loss: 0.3180 - val_accuracy: 0.8828\n",
      "Epoch 110/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2399 - accuracy: 0.9118 - val_loss: 0.3070 - val_accuracy: 0.8850\n",
      "Epoch 111/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2303 - accuracy: 0.9157 - val_loss: 0.3100 - val_accuracy: 0.8875\n",
      "Epoch 112/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2428 - accuracy: 0.9102 - val_loss: 0.3119 - val_accuracy: 0.8851\n",
      "Epoch 113/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2238 - accuracy: 0.9186 - val_loss: 0.3172 - val_accuracy: 0.8834\n",
      "Epoch 114/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2326 - accuracy: 0.9141 - val_loss: 0.2995 - val_accuracy: 0.8884\n",
      "Epoch 115/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2283 - accuracy: 0.9160 - val_loss: 0.3080 - val_accuracy: 0.8852\n",
      "Epoch 116/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2263 - accuracy: 0.9171 - val_loss: 0.3072 - val_accuracy: 0.8868\n",
      "Epoch 117/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2185 - accuracy: 0.9203 - val_loss: 0.3350 - val_accuracy: 0.8817\n",
      "Epoch 118/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2199 - accuracy: 0.9197 - val_loss: 0.3121 - val_accuracy: 0.8861\n",
      "Epoch 119/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2165 - accuracy: 0.9212 - val_loss: 0.3107 - val_accuracy: 0.8892\n",
      "Epoch 120/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2153 - accuracy: 0.9214 - val_loss: 0.3642 - val_accuracy: 0.8563\n",
      "Epoch 121/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.2397 - accuracy: 0.9111 - val_loss: 0.3164 - val_accuracy: 0.8829\n",
      "Epoch 122/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2105 - accuracy: 0.9235 - val_loss: 0.3643 - val_accuracy: 0.8727\n",
      "Epoch 123/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2098 - accuracy: 0.9237 - val_loss: 0.3056 - val_accuracy: 0.8890\n",
      "Epoch 124/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2041 - accuracy: 0.9260 - val_loss: 0.3066 - val_accuracy: 0.8890\n",
      "Epoch 125/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2120 - accuracy: 0.9228 - val_loss: 0.3575 - val_accuracy: 0.8746\n",
      "Epoch 126/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2063 - accuracy: 0.9251 - val_loss: 0.3185 - val_accuracy: 0.8877\n",
      "Epoch 127/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.2176 - accuracy: 0.9207 - val_loss: 0.3164 - val_accuracy: 0.8850\n",
      "Epoch 128/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2092 - accuracy: 0.9240 - val_loss: 0.3234 - val_accuracy: 0.8795\n",
      "Epoch 129/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1998 - accuracy: 0.9279 - val_loss: 0.3176 - val_accuracy: 0.8877\n",
      "Epoch 130/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1971 - accuracy: 0.9286 - val_loss: 0.3348 - val_accuracy: 0.8859\n",
      "Epoch 131/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1959 - accuracy: 0.9294 - val_loss: 0.3367 - val_accuracy: 0.8845\n",
      "Epoch 132/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1967 - accuracy: 0.9289 - val_loss: 0.3105 - val_accuracy: 0.8880\n",
      "Epoch 133/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1905 - accuracy: 0.9315 - val_loss: 0.3334 - val_accuracy: 0.8855\n",
      "Epoch 134/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1883 - accuracy: 0.9323 - val_loss: 0.3198 - val_accuracy: 0.8871\n",
      "Epoch 135/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1898 - accuracy: 0.9318 - val_loss: 0.3340 - val_accuracy: 0.8850\n",
      "Epoch 136/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1818 - accuracy: 0.9351 - val_loss: 0.3250 - val_accuracy: 0.8828\n",
      "Epoch 137/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1892 - accuracy: 0.9319 - val_loss: 0.3308 - val_accuracy: 0.8854\n",
      "Epoch 138/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1892 - accuracy: 0.9319 - val_loss: 0.3335 - val_accuracy: 0.8862\n",
      "Epoch 139/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1821 - accuracy: 0.9349 - val_loss: 0.3423 - val_accuracy: 0.8868\n",
      "Epoch 140/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1792 - accuracy: 0.9359 - val_loss: 0.3359 - val_accuracy: 0.8882\n",
      "Epoch 141/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1761 - accuracy: 0.9372 - val_loss: 0.3874 - val_accuracy: 0.8729\n",
      "Epoch 142/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2105 - accuracy: 0.9233 - val_loss: 0.3261 - val_accuracy: 0.8874\n",
      "Epoch 143/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1711 - accuracy: 0.9391 - val_loss: 0.3431 - val_accuracy: 0.8857\n",
      "Epoch 144/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1690 - accuracy: 0.9400 - val_loss: 0.3532 - val_accuracy: 0.8844\n",
      "Epoch 145/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1800 - accuracy: 0.9354 - val_loss: 0.3426 - val_accuracy: 0.8820\n",
      "Epoch 146/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1675 - accuracy: 0.9405 - val_loss: 0.3376 - val_accuracy: 0.8869\n",
      "Epoch 147/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1675 - accuracy: 0.9404 - val_loss: 0.3504 - val_accuracy: 0.8848\n",
      "Epoch 148/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1926 - accuracy: 0.9302 - val_loss: 0.3428 - val_accuracy: 0.8710\n",
      "Epoch 149/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2079 - accuracy: 0.9250 - val_loss: 0.3414 - val_accuracy: 0.8864\n",
      "Epoch 150/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1644 - accuracy: 0.9415 - val_loss: 0.3499 - val_accuracy: 0.8842\n",
      "Epoch 151/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1708 - accuracy: 0.9389 - val_loss: 0.3550 - val_accuracy: 0.8848\n",
      "Epoch 152/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1621 - accuracy: 0.9426 - val_loss: 0.3617 - val_accuracy: 0.8863\n",
      "Epoch 153/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1717 - accuracy: 0.9387 - val_loss: 0.3584 - val_accuracy: 0.8857\n",
      "Epoch 154/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1581 - accuracy: 0.9440 - val_loss: 0.3587 - val_accuracy: 0.8843\n",
      "Epoch 155/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1601 - accuracy: 0.9432 - val_loss: 0.3490 - val_accuracy: 0.8858\n",
      "Epoch 156/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1570 - accuracy: 0.9445 - val_loss: 0.3631 - val_accuracy: 0.8856\n",
      "Epoch 157/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1548 - accuracy: 0.9454 - val_loss: 0.3813 - val_accuracy: 0.8843\n",
      "Epoch 158/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1564 - accuracy: 0.9446 - val_loss: 0.3622 - val_accuracy: 0.8846\n",
      "Epoch 159/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1542 - accuracy: 0.9456 - val_loss: 0.3576 - val_accuracy: 0.8829\n",
      "Epoch 160/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1699 - accuracy: 0.9393 - val_loss: 0.3670 - val_accuracy: 0.8820\n",
      "Epoch 161/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1564 - accuracy: 0.9446 - val_loss: 0.3636 - val_accuracy: 0.8835\n",
      "Epoch 162/500\n",
      "108/108 [==============================] - 10s 95ms/step - loss: 0.1544 - accuracy: 0.9454 - val_loss: 0.3754 - val_accuracy: 0.8841\n",
      "Epoch 163/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1799 - accuracy: 0.9351 - val_loss: 0.3499 - val_accuracy: 0.8829\n",
      "Epoch 164/500\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.1536 - accuracy: 0.9457 - val_loss: 0.3852 - val_accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd3c2b2910>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_images, train_masks,  batch_size=BATCH_SIZE, verbose=1, epochs=EPOCHS, validation_data=(val_images, val_masks), callbacks = build_callbacks())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d6431d7-580c-4cd1-a27f-f05e51da3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_masks(raw, mask):\n",
    "    #mask is (512,512, 1)\n",
    "    \"\"\"...\n",
    "    .\n",
    "    ...\"\"\"\n",
    "\n",
    "    #mask1 = np.argmax(mask, axis=-1)\n",
    "    \"\"\"...\n",
    "   .\n",
    "   ...\"\"\"\n",
    "\n",
    "  \n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e12e7778-27ad-4b01-9e67-f55a9d698e32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n",
      "target_msk (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "sample_dir = \"samples_multiclass\" #where to save the predictions\n",
    "\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_img = test_images[i]\n",
    "    test_mask = test_masks[i]\n",
    "    combined = plot_img_and_masks(test_img, test_mask)\n",
    "    cv2.imwrite(sample_dir + \"/\" + str(i) + '.jpg', combined * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4fe57a8f-0fbe-41b6-b66e-ed1fe5b0241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS for multiclass segmentation\n",
      "mean iou 0.6305104021540022\n",
      "[0.7761108147097731, 0.7975325184374651, 0.31788787331476853]\n",
      "dice coeff. 0.7479093359093015\n",
      "[0.8739441348839421, 0.8873636613047017, 0.48242021153926073]\n",
      "pixel acc. 0.7137804462739031\n",
      "[0.8619959719020343, 0.9143704947353689, 0.36497487218430613]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Quantitative measures\"\"\"\n",
    "\n",
    "from evaluation_multiclass import mean_iou_test, dice_coeff, pixel_accuracy\n",
    "\n",
    "print(\"TEST RESULTS for multiclass segmentation\")\n",
    "pred_masks_one_hot = model.predict(test_images) #(n examples,h,w,3)\n",
    "\n",
    "#test_masks1 = np.argmax(test_masks, axis=-1) #(n examples,h,w)\n",
    "pred_masks = np.argmax(pred_masks_one_hot, axis=-1)\n",
    "\n",
    "iou, iou_classes = mean_iou_test(test_masks, pred_masks,num_classes=3)\n",
    "print(\"mean iou\", iou)\n",
    "print(iou_classes)\n",
    "dice, dice_classes = dice_coeff(test_masks, pred_masks,num_classes=3)\n",
    "print(\"dice coeff.\", dice)\n",
    "print(dice_classes)\n",
    "acc, acc_classes = pixel_accuracy(test_masks, pred_masks,num_classes=3)\n",
    "print(\"pixel acc.\", acc)\n",
    "print(acc_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da0c72-395b-4bc1-9251-0c20d7d5f85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
